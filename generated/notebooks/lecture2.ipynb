{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lecture 2 &ndash; Why derivatives matter\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we illustrate the fundamental link between derivative and optimization.\n",
    "\n",
    "## Univariate optimization\n",
    "\n",
    "### Linear polynomial\n",
    "\n",
    "The arguably simplest functions are affine function so let's start with the minimization of an affine function.\n",
    "What is the minimum of $x + 1$ ?\n",
    "Let's plot this function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots\n",
    "x = range(-8, stop=8, length=50)\n",
    "p(x) = x + 1\n",
    "plot(x, p.(x), label=\"\")\n",
    "\n",
    "ReLU(x) = (x < 0) ? 0.0 : x\n",
    "plot(x, p.(x), label=\"\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to plot, we generate `100` equally spaced numbers between `-8` and `8`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the elements in this range by converting into a vector with `collect`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "collect(x)\n",
    "\n",
    "p.(x)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quadratic polynomial\n",
    "\n",
    "What is the minimum of $x^2 - 2x + 1$ ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x = range(0, stop=2, length=50)\n",
    "p(x) = x^2 - 2x + 1 # (x - 1)^2\n",
    "plot(x, p.(x), label=\"\")\n",
    "scatter!([1], [p(1)], label=\"\")\n",
    "\n",
    "plotly()\n",
    "\n",
    "ε = 1e-1\n",
    "c = 0.1\n",
    "f = ReLU\n",
    "x0 = range(c-ε, stop=c+ε, length=50)\n",
    "plot(x0, f.(x0), label=\"\", linewidth=4, ratio=:equal)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dp(x) = 2*(x - 1)\n",
    "plot(x, dp.(x), label=\"\")\n",
    "scatter!([1], [dp(1)], label=\"\")\n",
    "\n",
    "plot(x, p.(x), label=\"\")\n",
    "tangent(x, y) = p(x) + (y - x) * dp(x)\n",
    "@show dp(2)\n",
    "y2 = range(1, stop=3, length=100)\n",
    "plot!(y2, tangent.(2, y2))\n",
    "@show dp(4)\n",
    "y4 = range(3, stop=5, length=100)\n",
    "plot!(y4, tangent.(4, y4))\n",
    "@show dp(1)\n",
    "y1 = range(0, stop=2, length=100)\n",
    "plot!(y1, tangent.(1, y1))\n",
    "y_1 = range(-2, stop=0, length=100)\n",
    "plot!(y_1, tangent.(-1, y_1))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quartic univariate polynomial:\n",
    "\n",
    "How to minimize $x^4 - 8x^3 + 4x^2 - 6x + 1$ ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots\n",
    "x = range(-3, stop=8, length=1000)\n",
    "p(x) = x^4 - 8x^3 + 4x^2 - 6*x + 1\n",
    "plot(x, p.(x))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Is that related to its derivative ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(x, x)\n",
    "plot(x, x.^2)\n",
    "plot(x, x.^5)\n",
    "plot(x, x.^4)\n",
    "plot(x, -x.^4)\n",
    "\n",
    "dp(x) = 4x^3 - 24x^2 + 8x - 6\n",
    "plot(x, dp.(x))\n",
    "\n",
    "ddp(x) = 12x^2 - 48x + 8\n",
    "plot(x, ddp.(x))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Is the zero-derivative condition sufficient ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x = range(-3, stop=64, length=1000)\n",
    "plot(x, x -> x * sin(x))\n",
    "\n",
    "plot(x, x .* cos.(x) + sin.(x))\n",
    "\n",
    "plot(x, cos.(x) - x .* sin.(x) + cos.(x))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zero derivative is necessary for $x$ to be a global minimizer but there are 3 cases of zero derivative:\n",
    "\n",
    "1. local minimum: when it's decreasing before $x$ and then increasing\n",
    "2. local maximum: when it's increasing before $x$ and then decreasing\n",
    "3. saddle point: when it's increasing (resp. decreasing) before $x$ and then increasing (resp. decreasing) after $x$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Say the first derivative of `f(x)` that is nonzero is the `k`-th derivative `f^{(k)}(x)` then\n",
    "* if `k` is odd then it is not a local extremum\n",
    "* if `k` is even and the value is positive then it is a local minimum\n",
    "* if `k` is even and the value is negative then it is a local maximum"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x = range(-1, stop=1, length=100)\n",
    "plot(x, -x.^5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multivariate optimization"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots\n",
    "x = range(-4, stop=4, length=100)\n",
    "y = range(-4, stop=4, length=100)\n",
    "p(x, y) = 2x^2 + x*y + 2y^2 - 2x + 3y + 1\n",
    "plotly()\n",
    "surface(x, y, p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "$z = p(x, y) = 2x^2 + xy + 2y^2 - 2x + 3y + 1$\n",
    "\n",
    "∂z/∂x\n",
    "∂z/∂y\n",
    "∂z/∂(x + y) = ∂z/∂x + ∂z/∂y\n",
    "∂z/∂(x + 2y) = ∂z/∂x + 2∂z/∂y\n",
    "\n",
    "$\\frac{\\partial p}{\\partial x} = 4x + y - 2$\n",
    "\n",
    "$\\frac{\\partial p}{\\partial y} = x + 4y + 3$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dx -> +1 -> 0 * 1 -> 0\n",
    "dy -> +2 -> 0 * 2 -> 0\n",
    "0 * 1 + 0 * 2 -> 0"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The notation $\\partial$ is defined such that $\\frac{\\partial y}{\\partial x} = 0$ and $\\frac{\\partial x}{\\partial y} = 0$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dpdx(x, y) = 4x + y - 2\n",
    "dpdy(x, y) = x + 4y + 3"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the plot, it seems $(1, -1)$ is close to be a local minimizer, is it ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p(1, -1)\n",
    "\n",
    "dpdx(1, -1)\n",
    "\n",
    "dpdy(1, -1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\frac{\\partial p}{\\partial x}$ is positive so it's increasing in $x$. So, should we increase or decrease $x$ to get closer to a local minimizer ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p(1, -1)\n",
    "\n",
    "p(1.1, -1)\n",
    "\n",
    "p(0.75, -1)\n",
    "\n",
    "p(0.74, -1)\n",
    "\n",
    "p(0.77, -1)\n",
    "\n",
    "p(0.78, -1)\n",
    "\n",
    "dpdx(0.75, -1)\n",
    "\n",
    "dpdy(0.75, -1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's constant in $x$ but decreasing in $y$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p(0.75, -0.94)\n",
    "\n",
    "p(0.75, -0.93)\n",
    "\n",
    "p(0.75, -0.938)\n",
    "\n",
    "p(0.75, -0.939)\n",
    "\n",
    "p(0.75, -0.937)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The *gradient* is defined as the concatenation of all the partial derivatives.\n",
    "Having a zero gradient is **necessary** to be a local minimizer. Again, it's not **sufficient** as it could also be a local maximizer or a saddle point."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "∇p(x, y) = [dpdx(x, y), dpdy(x, y)]\n",
    "\n",
    "-∇p(0.75, -0.938)\n",
    "\n",
    "x = 0.75\n",
    "y = -0.938\n",
    "\n",
    "xnew = x - 0.2 * dpdx(x, y)\n",
    "\n",
    "ynew = y - 0.2 * dpdy(x, y)\n",
    "\n",
    "x, y = x - 0.2 * dpdx(x, y), y - 0.2 * dpdy(x, y)\n",
    "\n",
    "v = [x, y]\n",
    "\n",
    "∇p(v...)\n",
    "\n",
    "function gradient_descent(h, num_iters = 100, v = [1, -1])\n",
    "    for _ in 1:num_iters\n",
    "        v = v - h * ∇p(v...)\n",
    "    end\n",
    "    return v\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With a step size of `1`, we diverge"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "v = gradient_descent(1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With a step size of `0.1`, we converge"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "v = gradient_descent(0.1)\n",
    "\n",
    "v = @time gradient_descent(0.001, 1000000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the solution, it looks rational"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rationalize.(v, tol=1e-14)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that with a step size above `0.4` we do not converge\n",
    "and below `0.4` you converge.\n",
    "What happens with a step size of exactly `0.4` ?\n",
    "With the step 0.4: you converge to an orbit of period 2:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "v = gradient_descent(0.4, 100)\n",
    "v1 = rationalize.(v, tol=1e-10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "At the next step, we get another one"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "v = gradient_descent(0.4, 101)\n",
    "v2 = rationalize.(v, tol=1e-10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then we cycle"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "v = gradient_descent(0.4, 102)\n",
    "rationalize.(v, tol=1e-10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indeed, here is the difference:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "v1 - v2"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With a step from `v1`, we go form `v1` to `v2`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "4 // 10 * ∇p(v1...)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With a step from `v2`, we go back to `v1`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "4 // 10 * ∇p(v2...)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now what happens with a step too small ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "gradient_descent(0.001, 1000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With a bit more steps ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "gradient_descent(0.001, 1000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And with even more steps ?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "gradient_descent(0.001, 10000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, we observed that\n",
    "\n",
    "* With a step size that is *too large* (in this case larger than 0.4),\n",
    "  the gradient method may diverge.\n",
    "* With a step size that is *too small*,\n",
    "  the method will converge but very slowly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient method\n",
    "\n",
    "A local minimizer of $f(x)$ can be found numerically as follows:\n",
    "\n",
    "1. Compute gradient $\\nabla f(x)$\n",
    "2. If approximately zero -> done\n",
    "3. Follow direction $-\\nabla f(x)$, find how long you follow it: line search and go to 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For our example, $\\nabla p(x, y) = 0$ is a linear system so we can find the global minimizer by solving this system:\n",
    "$$4x + y = 2$$\n",
    "$$x + 4y = -3$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A = [\n",
    "    4 1\n",
    "    1 4\n",
    "]\n",
    "\n",
    "b = [2, -3]\n",
    "\n",
    "x, y = A \\ b\n",
    "\n",
    "dpdx(x, y)\n",
    "\n",
    "dpdy(x, y)\n",
    "\n",
    "∇p(x, y)\n",
    "\n",
    "rationalize(x)\n",
    "\n",
    "rationalize(y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finding minimizers numerically with JuMP"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "pkg\"add NLopt\"\n",
    "\n",
    "using JuMP\n",
    "import NLopt\n",
    "model = Model(NLopt.Optimizer)\n",
    "set_optimizer_attribute(model, \"algorithm\", :LD_MMA)\n",
    "set_optimizer_attribute(model, \"ftol_rel\", 1e-16)\n",
    "set_optimizer_attribute(model, \"xtol_rel\", 1e-16)\n",
    "\n",
    "@variable(model, x)\n",
    "\n",
    "@variable(model, y)\n",
    "\n",
    "p(x, y)\n",
    "\n",
    "@objective(model, Min, p(x, y))\n",
    "\n",
    "model\n",
    "\n",
    "println(model)\n",
    "\n",
    "JuMP.optimize!(model)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "NLopt found a point with gradient zero and for which the function is locally increasing in every direction around the point. It therefore knows that it is a local minimizer but does not know whether it is a global minimizer. For this reason, its termination status is `LOCALLY_SOLVED`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solution_summary(model)\n",
    "\n",
    "value(x)\n",
    "\n",
    "value(y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can try as well with Ipopt without having to change the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pkg\"add Ipopt\"\n",
    "\n",
    "using Ipopt\n",
    "set_optimizer(model, Ipopt.Optimizer)\n",
    "\n",
    "JuMP.optimize!(model)\n",
    "\n",
    "solution_summary(model)\n",
    "\n",
    "value(x)\n",
    "\n",
    "value(y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's important to check for the `solution_summary` to check that it's `LOCALLY_SOLVED`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using JuMP\n",
    "model = Model(Ipopt.Optimizer)\n",
    "@variable(model, x)\n",
    "@variable(model, y)\n",
    "@objective(model, Max, p(x, y))\n",
    "JuMP.optimize!(model)\n",
    "\n",
    "value(x)\n",
    "\n",
    "value(y)\n",
    "\n",
    "solution_summary(model)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, it is `NORM_LIMIT` because it is unbounded"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.7",
   "language": "julia"
  }
 },
 "nbformat": 4
}
